{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "\n",
    "class Hypothesis(BaseModel):\n",
    "    claim: str = Field(..., description=\"The claim of the hypothesis being tested.\")\n",
    "    priors: List[str] = Field(..., description=\"A list of scientifically backed priors that validate the hypothesis.\")\n",
    "\n",
    "# I think about this like: this set of priors make this claim a valid hypothesis\n",
    "# Could later add something like \"evidence\" to support the priors or other things like that\n",
    "# Could even experiment with making the priors a list of Fact() instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = \"gpt-4o-mini\"\n",
    "SYS_MSG = \"\"\"\n",
    "You are a helpful research assistant.\n",
    "    Users will ask a question regarding whether or not the paper presents evidence forward or against a given argument,\n",
    "    You will output ONLY 2 things:\n",
    "    - argument: the argument presented by the paper regarding the user's query, like: \"Yes this paper validates this idea by discussing....\" etc..\n",
    "    - evidence: a list of DIRECT QUOTES from the paper containing information that support the argument above.\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RESEA RCH ARTICL E\\nImprovements tovisual working memory\\nperformance with practice and feedback\\nKirsten C.S.Adam1,2*,Edward K.Vogel1,2,3\\n1Department ofPsychology, Univers ityofChicago, Chicago, Illinois, United States ofAmerica, 2Institute for\\nMind andBiology, University ofChicago, Chicago, Illinois, United States ofAmerica, 3Grossman Institute for\\nNeurosc ience, Quantitativ eBiology, andHuman Behavio r,University ofChicag o,Chicago, Illinois, United\\nStates ofAmerica\\n*kadam1@ uchicago.e du\\nAbstract\\nVisual working memory capacity isestimated tobearound 3–4items, butonsome trials par-\\nticipants failtocorrectly report even asingle item from thememory array. Such failures of\\nworking memory performance aresurprisingly common, andparticipants have poor self-\\nawareness ofthem. Previous work hasshown thatbehavioral feedback canreduce thefre-\\nquency ofworking memory failures, butthebenefits offeedback disappeared immediately\\nafter itwas taken away. Here, wetested whether extended practice with orwithout trial-by-\\ntrialfeedback would lead topersistent improvements inworking memory performance. Par-\\nticipants were assigned tooneoffour groups: (1)Working memory practice with feedback\\n(2)Working memory practice without feedback (3)Crossword puzzle active control (4)No-\\ncontact control. Consistent with previous work, simple practice with avisual working mem-\\norytask robustly improved working memory performanc eacross practice sessions. How-\\never, wefound only partial support fortheefficacy offeedback inimproving working memory\\nperformance. Practicing with feedback improved working memory performance relative toa\\nno-feedback group forsome practice sessions. However, thefeedback benefits didnotper-\\nsistacross alltraining sessions anddidnottransfer toafinal testsession without thefeed-\\nback. Thus, thebenefits ofperformance feedback didnotpersist over time. Further, we\\nfound only stimulus-specific transfer ofvisual working memory practice benefits. Wealso\\nfound thatparticipants’ metaknowledge improved with practice, butthatreceiving feedback\\nabout task accuracy actually slightly harmed theaccuracy ofconcurrent metaknowled gerat-\\nings. Finally, wediscuss important design considerations forfuture work inthisarea (e.g.\\npower, expectations, and“spacing effects”). Forexample, wefound thatachieved statistical\\npower todetect abetween-groups effect declined with practice. This finding haspotentially\\ncritical implications foranystudy using a1-session study tocalculate power foraplanned\\nmulti-session study.\\nPLOS ONE |https://doi.or g/10.137 1/journal.po ne.02032 79 August 30,2018 1/22a1111111111\\na1111111111\\na1111111111\\na1111111111\\na1111111111\\nOPEN ACCESS\\nCitation: Adam KCS, Vogel EK(2018)\\nImproveme ntstovisual working memory\\nperforman cewithpractice andfeedback. PLoS\\nONE13(8): e0203279. https://doi.o rg/10.1371/\\njournal.pone .0203279\\nEditor: Enzo Tagliazucch i,Buenos Aires Physics\\nInstitute, ARGENT INA\\nReceived: March 5,2018\\nAccepted: August 19,2018\\nPublished: August 30,2018\\nCopyright: ©2018 Adam, Vogel. Thisisanopen\\naccess article distributed under theterms ofthe\\nCreative Commons Attribution License, which\\npermits unrestricte duse,distribu tion,and\\nreproduction inanymedium, provided theoriginal\\nauthor andsource arecredited.\\nData Availabilit yStatement: Thedataareavailable\\nonline onOpen Science Framework athttps://o sf.\\nio/839dz/.\\nFunding: Research wassupporte dbyNational\\nInstitute ofMental Health grant MH0872 14toE.V.\\n(https://w ww.nimh.ni h.gov) andbyOffice ofNaval\\nResearch grant N00014-12- 1-0972 toE.V.(https://\\nwww.onr.na vy.mil/). Thefunders hadnorolein\\nstudy design, datacollection andanalysis, decision\\ntopublish, orpreparation ofthemanuscript.\\nCompeting interests :Theauthors have declared\\nthatnocompeting interests exist.',\n",
       " 'Introduction\\nWorking memory isakeycognitive ability that helps usnavigate theworld around us.Weuse\\nworking memory totemporarily hold information inanactive state and tomanipulate itinaid\\nofourcurrent goals. Because ofitsimportance forintelligent behaviors, there hasgreat interest\\ninimproving working memory through “training” manipulations where working memory\\ndemands become progressively more difficult over time [1–3]. Even without anadaptive train-\\ningdesign, working memory performance greatly improves over time with simple practice [4].\\nHere, wetested whether behavioral feedback aimed atreducing failures ofvisual working\\nmemory performance could augment simple practice benefits, and whether practice-related\\nworking memory benefits might lead toimprovement onother cognitive tasks.\\nWhat areworking memory failures, and why target them with feedback? Using awhole\\nreport working memory task, wecanmeasure trial-by-trial fluctuations inworking memory\\nperformance and identify failures [5,6]. Inthistask, participants briefly view anarray ofcol-\\nored squares, remember them forashort duration, and then arerequired toreport allitems\\nfrom thearray. Accuracy foreach trial isscored asthenumber ofcorrectly reported items. By\\nholding memory load constant atadifficult set-size (e.g. 6items), wecanmeasure endogenous\\nfluctuations inperformance. Inthistask, most participants have amode of3items correct\\n(and model fitsareconsistent with amostly common capacity of3items), butthey differ in\\nhow frequently they failtoreach thistypical capacity limit. Surprisingly frequently (~12% of\\ntrials), participants perform nobetter than chance (0or1correct). Other studies using change\\ndetection similarly have found that participants hadlapses forasimilar proportion oftrials [7].\\nMind wandering and attentional lapses occur frequently ineveryday life[8–10], and lapses of\\nattention influence allsorts ofcognitive tasks, including working memory tasks. Assuch,\\nreducing failures represents apotentially fruitful way toimprove cognitive performance across\\nawide variety ofdomains. This isinpart because ofthesimplicity ofthegoal. Rather than try-\\ningtoboost maximal performance, wecansimply trytoeliminate abject failures.\\nThe current study isrelated to,butdistinct from, thebroader “working memory training”\\nliterature. First, wefocus specifically onpractice benefits toavisual working memory task\\n(which involves storage ofcolor-space pairings) [5,6]. Some work hascharacterized training of\\nvisual working memory [11,12], butthevast majority oftheworking memory training litera-\\nture hasemployed either thedual n-back task (which contains auditory and visual information\\nand involves updating over time) orcomplex span tasks (which may contain verbal, numerical,\\norspatial information, and involve both “storage” and “processing” demands) [2,3,13,14]. Sec-\\nond, ourexperimental design compares working memory gains with practice alone versus\\npractice with performance feedback. Here, weheld task difficulty (setsize) constant through-\\noutpractice. Incontrast, themajority oftheliterature focuses onhow well “adaptive” training\\ndesigns may improve working memory performance (and whether these performance gains\\ntransfer toother domains).\\nPrevious work hasshown that visual working memory performance canbeimproved by\\ngiving participants trial-by-trial feedback about accuracy. The most effective working memory\\nfeedback focused participants onreducing failures rather than attempting tostore more items\\n[15]. Inthisfeedback design, points were awarded fortrials with atleast 3items correct, and\\npoints were subtracted fortrials that didnotreach thisgoal. Thus, thisfeedback structure used\\naweighted combination ofboth positive and negative feedback, and thisweighted combina-\\ntion wasmore effective than positive feedback alone (e.g. +1point peritem). With weighted\\nfeedback, participants’ performance dramatically improved inblocks with feedback compared\\ntowithout feedback. The improvement toworking memory with weighted feedback islikely\\nduetoacombination ofimproved awareness offailures, motivation toreduce these failures\\nWorking memory practice andfeedback\\nPLOS ONE |https://doi.or g/10.137 1/journal.po ne.02032 79 August 30,2018 2/22',\n",
       " '[16], and changes totask strategy (for further discussion see[15]). Unfortunately, this\\nimprovement disappeared shortly after feedback wastaken away. Inawithin-subjects design,\\nparticipants who received feedback inthefirst halfoftheexperiment experienced more fail-\\nures immediately after thetrial-by-trial feedback wastaken away. Brief exposure tofeedback\\nmay have been insufficient toproduce lasting benefits onworking memory performance.\\nDespite therelatively high frequency ofworking memory failures, participants arerelatively\\nunaware ofthem. Previously, wefound that participants hadpoor meta-awareness ofworking\\nmemory failures, catching them only around 30% ofthetime [17]. Thus, wehypothesized that\\nfeedback may beeffective inimproving working memory performance because ithelps to\\ncounter-act deficiencies inmetaknowledge. Extensive exposure toexternal feedback may be\\nnecessary tobring about improvements inmetaknowledge.\\nTotestthepotential forextensive feedback toprovide lasting benefits toworking memory\\nperformance, wehadtwogroups ofparticipants complete 6practice sessions ofaworking\\nmemory task. One group completed thepractice sessions with trial-by-trial feedback, theother\\ngroup received nofeedback. Wealso included anactive control group (crossword puzzle prac-\\ntice) and apassive control group (no-contact) tomeasure baseline changes inworking mem-\\noryperformance over time. Wepredicted that practicing with feedback would lead tostronger\\nimprovements inworking memory performance, and that itwould also lead toimprovements\\ninparticipant’s meta-awareness ofworking memory failures. Wefound robust effects ofprac-\\nticeonworking memory performance that were modestly augmented bythepresence offeed-\\nback. However, wedidnotfind evidence that feedback improves metaknowledge and wealso\\nfound no“transfer” ofworking memory practice benefits toother cognitive tasks (visual\\nsearch, antisaccade, Raven’s matrices).\\nFinally, wereport theresults ofmeasures included toassess thevalidity ofourdesign and\\nparticipants’ expectations forimprovement. First, weconducted post-hoc power analyses on\\ncurrent and previously published data, and wefound that exposure tothetask (i.e.practice\\neffects) lowered power todetect abetween-subjects effect. This decrease inpower with practice\\nmay beimportant forplanning new multi-session training studies with abetween-groups\\neffect. Inaddition, weincluded measures ofparticipants’ effort, perceived improvement, and\\nattitudes toward themalleability ofintelligence. Subjective measures ofeffort and perceived\\nimprovement allowed ustotestwhether participants’ expectations were matched across train-\\ningand control groups. Wealso included measures ofsubjects’ beliefs about intelligence (e.g.\\nTheories ofIntelligence Scale [18]) totestwhether individuals’ beliefs predicted thedegree of\\nmotivation- orplacebo-related improvement from pre- topost-test (regardless oftraining\\ngroup). Forexample, prior work byJaeggi etal.[19] examining theories ofintelligence [18,20]\\nand working memory (n-back) training found that participants reporting more “fixed”\\ntheories ofintelligence (e.g. “You can’t really change how intelligent youare”) showed less\\nimprovement from pre- topost-test, regardless oftheir training group (i.e.n-back versus active\\ncontrol).\\nMaterials and methods\\nParticipants\\nProcedures were approved bytheUniversity ofOregon Institutional Review Board. Partici-\\npants were recruited from theUniversity ofOregon and thesurrounding community and pro-\\nvided written, informed consent. They were between theages of18and 35(M=20.5,\\nSD=2.66), and they self-reported normal orcorrected-to-normal visual acuity and normal\\ncolor vision. Participants were paid atotal of$200 forcompleting allsessions (2-hour pre-test,\\n2-hour post-test, and six1-hour training sessions). They received $30after thepre-test session.\\nWorking memory practice andfeedback\\nPLOS ONE |https://doi.or g/10.137 1/journal.po ne.02032 79 August 30,2018 3/22',\n",
       " 'Upon completing all6training sessions and thepost-test, they received anadditional $170. If\\nparticipants chose towithdraw from thestudy early, they were compensated atapro-rated\\nrate fortheir participation ($3.75 per15min). Weinitially recruited 79subjects. Atotal of6\\nparticipants withdrew after thepre-test, and 1additional participant withdrew after thefirst\\ntraining session. This leftatotal of72subjects (48female) foranalysis (23, 25,and 24per\\ngroup). Atalater date, werecruited anadditional 35subjects toserve asapassive control\\ngroup. Atotal of2participants no-showed fortheir first scheduled appointment, and anaddi-\\ntional 4participants didnotreturn fortheir second appointment. This left29participants (22\\nfemale) forfinal analyses. These participants were paid $20total fora2-hour pre-test and $30\\ntotal fora2-hour post-test.\\nProcedures\\nParticipants completed a2-hour pre-test session, six1-hour training sessions, and a2-hour\\npost-test session. After thepre-test, participants were pseudo-randomly assigned tooneof\\nthree training groups. Pseudo-random assignment matched groups foraverage pre-test perfor-\\nmance across allpre-test tasks (color whole report, crossword puzzles, color change detection,\\norientation whole report, visual search, antisaccade, Raven’s), asdifferences inpre-test perfor-\\nmance often prevent sensible interpretation ofresults [13]. Todoso,werandomly shuffled\\ngroup assignment until alltasks yielded nomain effect ofGroup (p>.05). Pseudo-randomiza-\\ntion wasperformed once after thefirst 3groups (“Working Memory—Feedback”, “Working\\nMemory—No Feedback”, “Active Control”) completed thepre-test session butbefore any\\npractice sessions occurred. The fourth group (“Passive Control”) wasadded atalater date and\\nwasnotincluded inthepseudo-randomization procedure.\\nThe critical training group (“Working Memory, Feedback”, n=25)practiced thediscrete\\nwhole report task and received feedback during their training sessions. Asecond group\\n(“Working Memory, NoFeedback”, n=23)practiced thediscrete whole report task butdid\\nnotreceive anyfeedback about their performance. Athird group (“Active Control”, n=24)\\npracticed doing crossword puzzles. This active control group served asabaseline comparison\\ntoworking memory practice while attempting tocontrol forresearcher contact and expecta-\\ntions forimprovement [3,13]. Finally, afourth group ofsubjects (“Passive Control, n=29)\\ncompleted only thepre-test and post-test sessions. Given concerns about theplacebo effect\\ncausing differences inperformance forpassive control groups relative toactive control groups,\\nwewanted toinclude both.\\nDuring thepre-test and post-test sessions, participants completed sixcognitive tasks inthe\\nsame order (Color Change Detection, Color Whole Report, Orientation Whole Report, Visual\\nSearch, Antisaccade, Raven’s Advanced Progressive Matrices). During thepost-test session,\\nparticipants filled outsome questionnaires after completing allthecognitive tasks. Cognitive\\ntasks and questionnaires aredescribed below. During training sessions, participants were\\nrequired topractice their assigned task forthefullhour.\\nAllsessions took place inthelabinindividual testing rooms. Crossword puzzles and ques-\\ntionnaires were completed with pencil and paper; allother cognitive tasks were administered\\nonaPCrunning Windows XPwith a17-inch CRT monitor (refresh rate =60Hz). Stimuli\\nwere presented using MATLAB (The Mathworks, Natick, MA) with Psychtoolbox [21,22].\\nParticipants were seated approximately 60cmfrom themonitor.\\nTraining tasks\\nColor whole report. The color whole report task isaworking memory task that measures\\ntrial-by-trial fluctuations inperformance [5,6]. This task wasused both fortheWorking\\nWorking memory practice andfeedback\\nPLOS ONE |https://doi.or g/10.137 1/journal.po ne.02032 79 August 30,2018 4/22',\n",
       " 'Memory–Feedback group and fortheWorking Memory–No Feedback group. During each\\npractice session, participants completed whole report trials foronehour intotal; trials were\\ndivided into blocks of30trials each. The exact number ofblocks completed varied across par-\\nticipants (M=8.60,SD=.41). Critically, those intheFeedback group didnotcomplete adif-\\nferent number ofblocks persession compared tothose intheNoFeedback group (p=.41).\\nOneach trial (Fig 1),participants briefly viewed (250 ms) anarray of6colored squares and\\nremembered theitems across ablank delay (1,000 ms). Colors were chosen from asetofnine\\neasily discriminable colors (red, orange, yellow, green, blue, magenta, cyan, black, white). At\\ntest, place-holders containing a3x3grid ofallpossible colors appeared atthelocations ofthe\\nremembered items. The arrangement ofcolors intheresponse grid wasfixed. Participants\\nclicked thecolor intheplace-holder corresponding tothecolor that waspresented ateach of\\nthe6locations. Accuracy foreach trial wascalculated asthenumber ofcorrectly reported col-\\nors(out of6possible). After reporting colors forallitems, theplace-holders disappeared. The\\nNoFeedback group sawablank gray screen after completing each trial. The Feedback group\\nsawperformance feedback after completing each trial. After presentation offeedback ora\\nblank gray screen, thenext trial began after amouse click (followed bya1,000 msinter-trial\\ninterval). Performance feedback awarded participants points based ontheir performance. If\\nparticipants performed well, they accrued points (+1for3correct, +2for4correct, +3for5or\\n6correct). Ifthey performed poorly, they lostpoints orearned noadditional points (-2for0\\ncorrect, -1for1correct, 0for2correct). Inaddition, participants earned a“streak bonus” for\\nconsistently performing well; thestreak bonus wasequal tothenumber oftrials inarow that\\nparticipants gotatleast 3correct (e.g. 5trials inarow =+5). Points accrued across each block\\noftrials and reset to0atthebeginning ofeach new block. Each trial’s feedback screen showed\\nthenumber ofcorrect items, thenumber ofpoints gained orlost, total score forthecurrent\\nblock, and anoverall block high score. This points manipulation waspreviously shown tobe\\nvery effective atreducing thefrequency ofworking memory failures relative tonofeedback or\\ntosimple feedback [15].\\nWhile making responses, participants were asked toindicate their confidence byusing a\\nmouse-button press [17]. Ifthey were confident about anitem, they were instructed toreport\\nthecolor ofthat item byclicking with theleftmouse button. Ifthey feltlikethey were guessing,\\nthey were instructed toinstead usetheright mouse button torespond. These confidence\\nFig1.Trial procedure sforthecolor whole report task. Key trial events aredepicted from lefttoright. Particip ants remem bered\\nthelocations andcolors of6squares across ablank delay, then reported thecolor ateach location byclicking acolor in“response\\ngrids” with themouse. The arrangement ofcolors intheresponse grids wasthesame foralltrials and allparticipants .\\nhttps://d oi.org/10.1371 /journal.pone. 0203279.g001\\nWorking memory practice andfeedback\\nPLOS ONE |https://doi.or g/10.137 1/journal.po ne.02032 79 August 30,2018 5/22',\n",
       " 'ratings canbeused tocalculate subjects’ metaknowledge offluctuations inworking memory\\nperformance.\\nCrossword puzzles. Participants were given anew packet of3crossword puzzles towork\\nonduring each 1-hour practice session. Puzzles were acquired from Boatload ofCrosswords\\n(Boatload Puzzles, Yorktown Heights, NY, USA).\\nPre- and post-test tasks\\nColor change detection. Change detection isameasure ofworking memory capacity\\n[23]. Oneach trial, participants remembered anarray of4,6,or8briefly presented (150 ms)\\ncolored squares across ablank delay (1,000 ms). Colors were chosen from asetofnine easily\\ndiscriminable colors (red, orange, yellow, green, blue, magenta, cyan, orange, black, white). At\\ntest, asingle testsquare waspresented atthelocation ofoneoftheremembered items. The\\ncolor ofthetestsquare wasthesame ordifferent from theremembered color (50% probabil-\\nity). Ifthecolor wasthesame, participants pressed the“z”key; ifitwasdifferent they pressed\\nthe“/”key. Participants completed 5blocks of30trials each.\\nColor whole report. Stimuli and trial procedures were thesame asdescribed fortheNo\\nFeedback version ofthetraining task. Forthepre- and post-test assessments, participants com-\\npleted 4blocks of25trials each. Unless participants intheFeedback group can“transfer” feed-\\nback-related performance improvements tolater task contexts (without feedback), then we\\nwould expect nomain effect offeedback group during thepost-test.\\nOrientation whole report. This task wasvery similar tothecolor whole report task.\\nInstead ofremembering color, participants instead remembered orientations ofcircles with\\nwedges cutoutfrom them (“wrench-head” stimuli). Orientations were chosen from oneof4\\nvalues (up, down, left,orright). Oneach trial, participants briefly viewed (200 ms) anarray of\\n6orientation stimuli and remembered thearray across ablank delay (1,150 ms). Attest, place-\\nholders appeared ateach oftheremembered locations. These placeholders contained “cross-\\nhairs” (intersected vertical and horizontal lines). Participants clicked thearm ofthecross-hair\\nthat matched theremembered orientation. After participants responded toallitems, theplace-\\nholders disappeared. The next trial began after aspacebar press (followed bya500msinter-\\ntrial interval). Participants completed 2blocks of30trials each.\\nVisual search. Visual search measures how quickly participants canfind atarget among\\ndistractors. Participants searched foranupright “L”among homogenous distractors (the letter\\n“T”rotated 0,90,180, or270degrees). The vertical part ofthetarget “L”wasslightly offset so\\nthat itmore closely matched theupside-down “T”distractors. Participants pressed theleft\\narrow keyiftheslightly longer side ofthe“L”target wasfacing left,and they pressed theright\\narrow keyifitwasfacing right. The number ofdistractors ranged from 1to8.There were 5\\nblocks of48trials.\\nAntisaccade. The antisaccade task isameasure ofattention and cognitive control\\n[24,25]. Participant fixated across inthecenter ofthescreen. After anunpredictable duration\\n(.2–2.2 seconds), acue(“=“) quickly flashed totheleftorright offixation. The cueflashed\\ntwice (100 mson,50msoff,100mson). Following a50msdelay, atarget appeared inthe\\nopposite hemifield for100ms.The target was theletter “P”, “B”, or“R”. Following a50ms\\ndelay, thetarget letter was masked twice (letter “H” for100ms,blank 50ms,number “8”for\\n100ms). Todetect thetarget, participants needed resist capture bythecueand quickly move\\ntheir attention and eyes totheopposite hemifield. Participants reported thetarget bypressing\\ntheletter “P”, “B”, or“R”onthekeyboard. Forcorrect trials, theentire screen flashed green\\nfor500ms.Forincorrect trials, theentire screen flashed red. There were 4blocks of36trials\\ntotal.\\nWorking memory practice andfeedback\\nPLOS ONE |https://doi.or g/10.137 1/journal.po ne.02032 79 August 30,2018 6/22',\n",
       " 'Raven’s Advanced Progressive Matrices. The Advanced Progressive Matrices task [26] is\\nameasure ofabstract reasoning ability and fluid intelligence. Foreach question, participants\\nviewed a3by3grid ofabstract geometric shapes. These shapes arerelated tooneanother (e.g.\\nanabstract rule dictates similarity across columns /rows ofthegrid). The bottom right corner\\nofthegrid ismissing, and participants must choose theitem that best belongs from oneof8\\nchoices. The fulltestis36questions that arepresented inascending order ofdifficulty. To\\nmeasure change from pre- topost-test, questions were divided into twosetsof18(even and\\nodd questions). Most participants received even questions atpre-test and odd questions post-\\ntest(due toclerical error, 4participants received odd questions atpre-test and even questions\\natpost-test). Participants were given 10minutes towork onthesetof18questions; scores\\nwere calculated asthetotal number ofcorrect questions.\\nTimed crossword puzzle. Participants were given 1crossword puzzle, and they were\\ngiven 10minutes work onthepuzzle. Participants were instructed that they should trytoget\\nasmany words correct aspossible intheallotted time. Crossword puzzle accuracy wasscored\\nasthetotal number ofcomplete, correct words perminute oftask time.\\nQuestionnaires\\nQuestionnaires were administered attheend ofthepost-test session. Allquestions and scales\\nadministered toparticipants areavailable onourOpen Science Framework page (https://osf.\\nio/839dz/). Wecollected information about subject demographics (e.g. age, handedness). In\\naddition, wewere interested inwhether participants thought that they improved from thepre-\\ntesttothepost-test. Wealso used afewdifferent questionnaires from Dweck (2000) tocharac-\\nterize theattitude ofparticipants inoursample towards learning and intelligence. Wereasoned\\nthat participants who thought they improved more orwho view intelligence asmore malleable\\nmight show greater practice benefits and/or placebo effects.\\nDemographic information and perceived performance. Wecollected participants’ age,\\ngender, native language(s), handedness, and parental education level. Wealso asked partici-\\npants toestimate their typical amount ofsleep pernight, and togive ratings oftheir average\\nlevels ofalertness and motivation across thetraining sessions. Inaddition, weasked partici-\\npants 6questions about their perceived level ofeffort and improvement across their completed\\nsessions. Anexample ofsubjects’ perceived effort isthestatement, “Ifound itdifficult tocare\\nvery much about how Iwasdoing onthetasks.” Anexample ofsubjects’ perceived perfor-\\nmance isthestatement, “Ifeelthat myperformance onthetasks improved from thefirst ses-\\nsion tothelastsession.” Participants rated their endorsement ofeach statement from 1\\n(strongly agree) to6(strongly disagree). Forease ofinterpretation, these measures areplotted\\nsuch that 6represents thestrongest agreement with each construct (e.g. more effort) rather\\nthan disagreement.\\nTheories ofintelligence scale foradults. This 8-question scale [18] quantifies partici-\\npants’ views onthemalleability ofintelligence. Participants rated their endorsement ofeach\\nstatement from 1(strongly agree) to6(strongly disagree). People who view intelligence as\\nmore fixed (“entity theorists”) aremore likely toendorse thestatement, “To behonest, you\\ncan’t really change how intelligent youare.” Those who view intelligence asmalleable (“incre-\\nmental theorists”) would endorse astatement such as,“You canchange even your basic intelli-\\ngence level considerably.”\\nGoal choice items questionnaire. This 4-item questionnaire places learning goals against\\nperformance goals [18]. Learning goals represent engaging inanactivity inwhich thepartici-\\npant would learn alot,butwould notnecessarily perform well. Performance goals represent\\nengaging inanactivity where theparticipant would excel, butnotnecessarily bechallenged\\nWorking memory practice andfeedback\\nPLOS ONE |https://doi.or g/10.137 1/journal.po ne.02032 79 August 30,2018 7/22',\n",
       " '[20]. Forexample, someone who values performance goals over learning goals would bemore\\nlikely toendorse thestatement, “Although Ihate toadmit it,Isometimes would rather dowell\\ninaclass than learn alot.” Previous work hasshown that people who view intelligence asmal-\\nleable aremore likely toendorse learning goals over performance goals [27].\\nConfidence inone’s intelligence. This 3-item measure asks participants torate their con-\\nfidence intheir intelligence [18]. This measure ismost often used toshow that those who view\\nintelligence asfixed versus malleable donotdiffer intheir confidence oroptimism toward\\ntheir own intelligence.\\nResults\\nImprovement onpracticed task\\nTotestwhether feedback differentially changed therate ofimprovement across allsessions, we\\nranamixed ANOVA with between-subjects factor Feedback and within-subjects factor Ses-\\nsion (Pre-test, 6training sessions, and Post-test). Wequantified behavioral performance ina\\ncouple ofways. First, welooked atmean performance (the average number ofcorrect items on\\neach trial). Second, welooked atthechange of“poor performance” trials (less than 3correct).\\nThe feedback manipulation used here incentivized participants toget3correct byawarding\\npoints only when thisgoal wasachieved. Consistent with thisincentive structure, wefound\\npreviously that thisfeedback manipulation hadthegreatest impact ontheproportion ofpoor\\nperformance trials [15]. Assuch, weexpectedapriori that thismeasure ofperformance should\\nbemost sensitive toanychanges inperformance.\\nWefound alarge main effect ofsession onmean performance, F(2.52,115.71) =30.0,p<\\n.001, ηp2=.40,and proportion ofpoor performance trials,F(3.23,148.42) =28.9,p<.001,\\nηp2=.39,indicating that practice ledtosignificant improvements inworking memory perfor-\\nmance (Fig 2).Note, theGreenhouse-Geisser correction isapplied where theassumption of\\nsphericity isviolated. There wasnomain effect offeedback foreither measure (p>.11). How-\\never, there wasasignificant interaction between feedback and session forthepoor-perfor-\\nmance measure, F(3.23,148.42) =3.68,p=.01, ηp2=.07,and atrending interaction forthe\\nmean performance measure, F(2.52,115.71) =2.33,p=.09, ηp2=.05.Post-hoc comparisons\\nrevealed that thelikely cause oftheinteraction wasbecause ofalarger difference between the\\nfeedback and no-feedback groups forearlier practice sessions. Two-tailed t-tests revealed a\\nsignificant difference intheproportion ofpoor performance trials foronly thefirst (p=.038)\\nand third (p=.045) practice sessions. Indeed, ANOVAs testing foraninteraction between\\npre-test scores and scores onthefirst session were significant (mean number correct,p=.004,\\nFig2.Improvem entinpracticed task over time. (A)Change inmean number correct fortheworking memory task. (B)Change in\\nproporti onlessthan 3correct fortheworking memory task. (C)Change incrossword puzzle performance (words perminute). Error\\nbars represent onestandard error ofthemean.\\nhttps://d oi.org/10.1371 /journal.pone. 0203279.g002\\nWorking memory practice andfeedback\\nPLOS ONE |https://doi.or g/10.137 1/journal.po ne.02032 79 August 30,2018 8/22',\n",
       " 'proportion poor performance trials,p=.002). Bydesign, there wasnodifference inpre-test\\nscores between groups. Thus, thissignificant interaction supports theconclusion that there\\nwasaninitial difference between feedback and nofeedback groups inthefirst practice session\\nthat didnotpersist across allpractice sessions.\\nWealso tested thehypothesis that participants inthefeedback group would develop supe-\\nrior meta-knowledge relative tothefeedback group (Fig 3).Wefound nosupporting evidence\\nforthishypothesis. Toquantify metaknowledge accuracy that isrelatively independent of\\noverall bias inconfidence reports, wecalculated a“metaknowledge correlation” foreach indi-\\nvidual participant. Todoso,weplotted thenumber ofcorrectly reported items foreach trial\\nagainst thenumber ofconfident items foreach trial then calculated thecorrelation coefficient\\n(Pearson’s) foreach participant. Note, some subjects occasionally used thesame button (“no\\nguess”) forallresponses within theentire session. Forthese subjects, thecorrelation coefficient\\nisundefined sothey areexcluded from theanalysis (total remaining: 18inno-feedback group,\\n20infeedback group). Wefound that metaknowledge performance increased over time, as\\nshown byincreased correlation strength,F(3.91,140.86) =6.58,p<.001, ηp2=.15.There was\\nalso amain effect offeedback, butnotinthepredicted direction. Those intheno-feedback\\ngroup hadhigher metaknowledge than those inthepredicted group,F(1,36) =11.0,p=.002,\\nηp2=.24,and there wasnointeraction between feedback and session,F(3.91,140.86) =1.4,p=\\n.24, ηp2=.04.Post-hoc paired t-tests revealed that there were nosignificant differences\\nbetween groups ineither thepre-test (p=.27) orpost-test sessions (p>.07). However, during\\nall6training sessions theno-feedback group hadhigher metaknowledge relative tothefeed-\\nback group (p<.001 top=.015). This indicates that themain effect ofgroup wasdependent\\nonthepresence offeedback; thebetween-groups differences went away when nofeedback was\\nadministered inthepost-test session.\\nAsasecond testofmetaknowledge that would notexclude anysubjects, weinstead looked\\natoverall level ofconfidence relative toactual performance (measured astheabsolute value of\\nthedifference between confidence and accuracy foreach trial). Unlike thefirst measure, this\\ndifference measure ismost similar tomeasures of“bias” inratings, rather than accuracy. For\\nthismeasure, values close to0would indicate better metaknowledge. This difference measure\\nrevealed thesame significant effect ofsession; participants’ metaknowledge improved across\\nsessions,F(3.07, 141.25) =3.99,p=.009, ηp2=.08.There wasagain amain effect offeedback\\nFig3.Improvem entinworking memory metaknowle dge with practice. (A)Metaknowle dgecorrelatio nmetric. Higher\\ncorrelatio nvalues indicate better metaknowl edge. (B)Absolute value ofthedifference between confiden ceand accurac yoneach\\ntrial. Values closer to0represent better metaknowl edge. Error bars represent onestandard error ofthemean.\\nhttps://d oi.org/10.1371 /journal.pone. 0203279.g003\\nWorking memory practice andfeedback\\nPLOS ONE |https://doi.or g/10.137 1/journal.po ne.02032 79 August 30,2018 9/22',\n",
       " 'group,F(1,46) =6.614,p=.013, ηp2=.13,and nofeedback bysession interaction (p=.32).\\nOnce again, themain effect ofgroup waslimited tosessions where feedback wasactually pre-\\nsented. There wasnosignificant difference between feedback groups foreither thepre-test\\n(p=.90) orpost-test sessions (p=.42). However, there wasasignificant difference between\\ngroups for4of6practice sessions (p<.05). Unlike thechange inmetaknowledge correlation\\ncoefficient, theobserved improvement over time waslimited tothechange from thepre-test to\\nthefirst practice session. Ifonly the6practice sessions were included intheANOVA, there\\nwasnomain effect ofsession (p=.29).\\nAcross ourtwomeasures ofmetaknowledge, wefound that practicing theworking memory\\ntask ledtoimproved metaknowledge (with orwithout feedback). However, thisimprovement\\nwasnotnecessarily acquired gradually over time; wefound inconsistent time-courses of\\nimprovement formetaknowledge accuracy (correlation measure) versus bias (difference mea-\\nsure). Surprisingly, wealso found that thepresence offeedback altered metaknowledge ina\\ncounter-intuitive way. Specifically, those who received trial-by-trial feedback hadworse meta-\\nknowledge relative tothose who didnotreceive anyfeedback. However, these differences did\\nnotcarry through toapost-test session with nofeedback. This surprising finding may indicate\\nthat those who received feedback paid lessattention tointernal judgments.\\nFinally, wechecked whether theactive control group (crossword puzzles) improved on\\ntheir practiced task over time (Fig 2C). Arepeated-measures ANOVA with factor Session\\nrevealed asignificant difference over time,F(3.57,78.56) =24.52,p<.001, ηp2=.53.This dif-\\nference wasnotentirely driven bythelarge risefrom thelastpractice session tothefinal post-\\ntest. There wasstillasignificant improvement across only the6practice sessions,F(5,110) =\\n4.67,p=.001, ηp2=.18,with asignificant linear trend (p=.01). Thus, itseems that participants\\nintheactive control group were effortfully engaged throughout thepractice sessions.\\nImprovement from pre-test topost-test\\nFirst, wecompared improvement from pre-test topost-test foreach ofthepracticed tasks. We\\nfound that those who were ineither ofthetwocolor whole report groups improved signifi-\\ncantly more onthecolor whole report post-test measure relative tocontrols. Data forallfour\\ngroups areplotted Fig4.Forthismeasure, there were nosignificant differences orbetween the\\ntwoworking memory groups (feedback vs.nofeedback, p=.97) orthetwocontrol groups\\n(passive vs.active,p=.67). Assuch, wecollapsed thedata into twogroups: “working memory\\npractice” and “control” groups. This analysis revealed asignificant interaction between group\\nand session, F(1,99) =51.68,p<.001, ηp2=.34.Those who practiced theworking memory\\ntask improved from pre- topost-testt(47) =7.66,p<.001, whereas those inthecontrol groups\\ndidnotimprove, t(52) =.13,p=.90.Ontheother hand, wedidnotfind asignificant interac-\\ntion between these groups forimprovement inmetaknowledge performance (absolute value of\\nnumber confident–number correct). Both groups improved their metaknowledge (p=.003),\\nbutthere wasnointeraction between group and metaknowledge improvement (p=.21). How-\\never, thismeasure isdifficult tointerpret, asthere were overall group differences atbaseline\\n(p=.02).\\nLikewise, participants inthecrossword puzzle group improved more onthecrossword puz-\\nzlepost-test relative totheother three groups. Data forallfour groups areplotted inFig4B.\\nAccuracy forthecrossword testwasquantified aswords perminute. One subject wasexcluded\\nfrom thecrossword puzzle analysis because ofaclerical error (their testwasnottimed topre-\\ncisely 10minutes, and they were instead allowed anunknown extra amount oftime towork).\\nThere wasnodifference inperformance foranyofthe3groups who didnotpractice thecross-\\nword puzzle task (feedback, nofeedback, and passive control),p=.68.Assuch, they were\\nWorking memory practice andfeedback\\nPLOS ONE |https://doi.or g/10.137 1/journal.po ne.02032 79 August 30,2018 10/22',\n",
       " 'collapsed into onegroup and compared tothecrossword puzzle group. Both thecrossword\\npuzzle practice group (p<.001) and thenon-crossword group (p<.001) improved from pre-\\ntopost-test. However, thecrossword group improved more than thenon-crossword group as\\nindicated byasignificant interaction between group and session, F(1,98) =8.78,p=.004, ηp2=\\n.08.\\nNext, weexamined whether practice onthecolor whole report working memory task ledto\\nimprovements ontheother twoworking memory tasks. These twotasks each differed inone\\naspect from thepracticed task. The color change detection task used thesame stimulus set(9\\ncolors) butrequired adifferent response (same ordifferent judgment). Conversely, theorien-\\ntation whole report task used adifferent stimulus set(4orientations), butused thesame\\nresponse mode (clicking each item).\\nWefound evidence forstimulus-specific benefits ofpractice (Fig 4).Those intheworking\\nmemory practice groups improved more oncolor change detection than didthose inthecon-\\ntrolgroups. There wasagain nodifference between thetwoworking memory groups (p=.86)\\norbetween thetwocontrol groups (p=.997) sothey were collapsed. Wefound asignificant\\ninteraction between group and session, F(1, 99)=14.91,p<.001, ηp2=.13,indicating that\\nthose who received working memory practice improved more than didthose inthecontrol\\ngroup. Infact, there wasnosignificant change inthecontrol group’s performance from pre- to\\npost-test, t(52) =1.09,p=.28.Unlike thecolor task, wedidnotfind anyevidence ofasystem-\\naticbenefit ofcolor working memory practice ontheorientation task. There were some\\nFig4.Change inperforman cefrom pre-tes ttopost-test forpracticed tasks and working memor ymeasure s.(A)Color whole\\nreport (B)Crossword puzzles (C)Color change detection (D)Orientatio nwhole report.\\nhttps://d oi.org/10.1371 /journal.pone. 0203279.g004\\nWorking memory practice andfeedback\\nPLOS ONE |https://doi.or g/10.137 1/journal.po ne.02032 79 August 30,2018 11/22',\n",
       " 'baseline differences inperformance across groups, sowedidnotcollapse into twogroups. We\\nfound asmall benefit ofpractice onperformance, F(1,51) =6.03,p=.02, ηp2=.06,butno\\ninteraction between group and session,p=.24.Welooked separately ateach group forevi-\\ndence ofimprovement from pre- topost- test, and wefound that only theno-contact control\\ngroup improved from pre- topost-test (p=.001). Thus, wefound noevidence that practice\\nwith acolor working memory task ledtoimprovement onanorientation task. Instead, we\\nconclude that thepractice benefits obtained were highly feature-specific, similar toprior work\\nexamining visual working memory training [11] (but also see[19,28]).\\nFinally, wefound nodifferences ingroups’ performance foranyoftheother cognitive\\ntasks (Raven’s, Antisaccade, Visual Search), asshown inFig5.However, wedidfind overall\\nimprovement onthese tasks from pre-test topost-test. Raven’s accuracy was scored asthe\\ntotal number ofcorrect items completed in10minutes. There was anincrease inaccuracy on\\ntheRaven’s from pre- topost-test, F(1,97) =48.47,p<.001, ηp2=.33,butnoeffect ofgroup,\\nF(3,97) =.29,p=.83, ηp2=.009, and nointeraction between group and performance, F(3,\\nFig5.Change inperforman cefrom pre-test topost-te st.(A)Antisaccade accuracy (B)Visual search average reaction time (C)\\nRaven’s Matrices .\\nhttps://do i.org/10.1371/j ournal.pone .0203279.g0 05\\nWorking memory practice andfeedback\\nPLOS ONE |https://doi.or g/10.137 1/journal.po ne.02032 79 August 30,2018 12/22',\n",
       " '97)=2.10,p=.11, ηp2=.06.Antisaccade performance was scored aspercent error (wrong\\nletter reported) and asaverage reaction time. There was anincrease inantisaccade accuracy\\nfrom pre- topost-test, F(1,97) =23.84,p<.001, ηp2=.20,butnoeffect ofgroup, F(3,97) =\\n1.27,p=.29, ηp2=.04,and nointeraction between group and performance, F(3, 97)=.29,\\np=.84, ηp2=.01.The same pattern ofresults was seen forreaction time. Finally, visual search\\nperformance was quantified astheaverage response time. Wefound improvement invisual\\nsearch reaction times from pre- topost-test, F(1,97) =17.61,p<.001, ηp2=.15,butnoeffect\\nofgroup, F(3,97) =1.56,p=.20, ηp2=.05,and nointeraction between group and perfor-\\nmance, F(3, 97)=1.41,p=.24, ηp2=.04.The same pattern ofresults was observed forsearch\\nslopes. Thus, practicing acolor working memory task didnotlead toanymarked improve-\\nment inother cognitive tasks.\\nCorrelations between measures and thereliability ofmeasures across pre- and post-test ses-\\nsions areshown inS1–S3 Tables intheSupporting Information. Reliabilities forvisual search\\nreaction times and forRaven’s matrices were particularly poor (r<.5),sothese tasks should\\nbeinterpreted with caution. Reliability values fortheworking memory tasks were quite abit\\nhigher forthecontrol group (r~.8)than fortheworking memory practice group (r~.6)pre-\\nsumably because there wassome variability inhow much participants’ benefited from practice\\n(thus reducing thecorrelation between pre- and post-test).\\nGrowth mindset didnotpredict performance improvement\\nNext, weexamined ourhypothesis that participants with agrowth mindset may show greater\\nimprovement relative tothose with afixed mindset. This effect might even bear outintasks\\nwhere wewould expect noimprovement duetopractice alone. That is,those who think they\\narecapable ofgrowth might bemore susceptible toexpectancy-based placebo effects. We\\nfound nosupport forthishypothesis.\\nTocreate asingle “growth mindset” score, were-ordered reverse-scored items and then\\naveraged across all8questions from theTheories ofIntelligence scale (Cronbach’s alpha ofthe\\n8items =.95). Ascore of1indicates thegreatest possible degree ofhaving agrowth or“incre-\\nmental mindset” whereas ascore of6indicates themaximum degree ofhaving a“fixed mind-\\nset”. The average growth mindset score was2.72 (SD =1.01, skew =.24), indicating that our\\nsample leaned toward having agrowth mindset (t-test compared toexpected middle score of\\n3.5,t(100) =7.82,p<.001, 95% CI[2.52, 2.92]).\\nForeach ofourcognitive measures, wecomputed adifference score (post-test–pre-test) as\\nameasure ofoverall task improvement. Wefound nosignificant correlation between task\\nimprovement and growth mind-set foranyofthetasks: Color Whole Report (r=-.01,p=.96),\\nCrossword Puzzles, (r=.17,p=.09), Color Change Detection (r=.07,p=.47), Orientation\\nWhole Report, (r=.05,p=.65), Raven’s (r=-.02, p=.82), Antisaccade accuracy (r=.02,p=\\n.84), orVisual Search speed (r=-.04, p=.67). Likewise, there were nosignificant correlations\\nbetween task performance and growth mindset when correlations were examined separately\\nforcontrol groups and working memory practice groups.\\nWealso computed composite scores forthe“goal choice” questionnaire and forthe“confi-\\ndence inintelligence” questionnaire. Wefound norelationship between thegrowth mind-set\\nscore and goal choice,r=.09,p=.39.Wealso found norelationship between growth mind-set\\nand confidence inintelligence, r=.18,p=.08.\\nDifferences inperceived improvement and effort across groups\\nWewere interested whether those indifferent groups reported subjective differences inper-\\nceived improvement oreffort (Fig 6).First, welooked atdifferences across all4groups using a\\nWorking memory practice andfeedback\\nPLOS ONE |https://doi.or g/10.137 1/journal.po ne.02032 79 August 30,2018 13/22',\n",
       " 'one-way ANOVA. Wefound that there wasnodifference inself-reported effort between\\ngroups, F(3,97) =1.67,p=.18.However, wedidfind asignificant difference inperceived\\nimprovement, F(3, 97)=3.12,p=.03.Byeye, thiseffect ofgroup appeared tobemostly driven\\nbythedifference between thetwoworking memory groups relative tothecontrols. Apost hoc\\ntestcollapsing into twogroups (“working memory task” or“control”), wefound adifference\\ninperceived improvement, F(1,99) =9.37,p=.003. Although wefound nolarge effect ofsub-\\njective effort across thefour groups, wenevertheless found differences inexpectation (as\\nindexed bysubjective perceived improvement). This result emphasizes how difficult itisto\\nfind control conditions that cantruly eradicate differences inexpectation and control forpla-\\ncebo effects [29].\\nPost-hoc power analyses based onprior work\\nWethink itisimportant toqualify these results with apower analysis and abrief discussion of\\nwithin- versus between-subjects manipulations instudies ofworking memory. Inearlier work,\\nwefound robust within-subject effects ofperformance feedback onworking memory perfor-\\nmance [15]. However, because individual differences inworking memory areboth large and\\nstable [4],theexpected sizeofanintervention’s effect istypically much smaller than therange\\nofindividual differences. Unfortunately, wedidnothave theforesight toconduct both within-\\nand between-subjects power analyses before collecting thisexperiment’s data. Post hoc, how-\\never, wecanillustrate theextent ofchange toexpected power forthesame effect runbetween\\nversus within subjects. Power estimates were calculated using theG\\x03power 3.1application\\n[30,31].\\nFirst, welooked attheeffect sizeand power forthefeedback effect observed inExperiment\\n3ofAdam and Vogel (2016), asthiswasthesame feedback manipulation used inthecurrent\\nstudy. InExperiment 3,participants received feedback forhalf oftheexperiment and nofeed-\\nback fortheother halfoftheexperiment. The order ofthese twoconditions wasblocked and\\ncounterbalanced across participants. The within-subjects effect offeedback reported inAdam\\nand Vogel (2016) wasvery strong, with acalculated effect sizeofd=.93and power (1−β)>\\n.99(n=52). Next, weinstead calculated effect sizeasbetween-subjects effects. Wecalculated\\nbetween-subjects power separately forthefirst halfand thesecond half oftheexperiment so\\nFig6.Difference insubjective effort and perceived improvem entacross groups. (A)Average subjective effort rating. (B)Average\\nperceived improvem entrating. Ratings were made onascale from 1to6.Inthisplot, 6represents thehighest level ofendorsem ent\\nofeffort and improvem ent.\\nhttps://d oi.org/10.1371 /journal.pone. 0203279.g006\\nWorking memory practice andfeedback\\nPLOS ONE |https://doi.or g/10.137 1/journal.po ne.02032 79 August 30,2018 14/22',\n",
       " 'that wecould seeifthecomputed effect sizechanged after subjects hadexposure tothetask\\n(i.e.after experiencing oneofthe2conditions during thefirst half oftheexperiment). Forthe\\nfirst half oftheexperiment, thebetween-subjects effect sizewasd=.78.With group sizes of24\\nand 28,wefound that power wassufficient, (1−β)=.79.Note, these sample sizes aresimilar\\ntotheones wechose forthepresent experiment. Unfortunately, however, thecalculated effect\\nsizedecreased inthesecond half oftheAdam and Vogel (2016) experiment. The effect sizefor\\nthesecond half oftheexperiment decreased tod=.51,(1−β)=.44.Thus, hadwerunthisfull\\nsetofanalyses before conducting thecurrent experiment, wemay have suspected that we\\nmight need larger group sizes tocounteract adecrease ineffect sizepotentially caused byprac-\\nticeeffects orsome other aspect ofprevious exposure tothetask. Forthefirst practice session\\ninthepresent study (after exposure tothetask inthepre-test), thedifference between thefeed-\\nback and nofeedback groups wascloser tothesecond, smaller effect found inAdam and\\nVogel (2016). Wecalculated aneffect ofsizeofd=.39,meaning that around 100subjects per\\ngroup would beneeded toachieve power (1−β)=.80todetect abetween-subjects effect\\nwithin thissingle session. Given therobust effects offeedback forourearlier within-subjects\\nmanipulation and ourrelatively lowpower here, wespeculate that thesmall effects offeedback\\nthat wesawwould hold upwith alarger between-groups sample. However, these results should\\nnevertheless beinterpreted conservatively; weseehints that feedback boosts practice benefits,\\nbutthese effects arerelatively short-lived. The relative effects offeedback appear todissipate as\\npractice effects increase.\\nDiscussion\\nFeedback canimprove working memory performance when itpoints participants toward an\\noptimal goal. Here, weasked whether practicing with feedback canhelp participants more\\nquickly and efficaciously reduce thefrequency ofworking memory failures. Our goal ofreduc-\\ningfailures with feedback issimilar to,butdistinct from, thegoal toincrease capacity through-\\noutthevery large “working memory training” literature [1–3]. Both goals would have the\\nsame consequence ofimproving overall working memory performance butwould relyupon\\ndistinct mechanisms and strategies. Wehypothesized that practicing with feedback relative to\\nwithout feedback would lead tofaster, more robust improvements inworking memory perfor-\\nmance and would also improve subjects’ awareness ofworking memory failures. Wefound\\nonly partial support forthese hypotheses. Consistent with ourpredictions, practicing with per-\\nformance feedback increased working memory performance relative topracticing without\\nfeedback. However, thesizeofthiseffect wasrather small and didnotpersist over time. Rela-\\ntivetotheno-feedback group, participants inthefeedback group more successfully reduced\\nthefrequency ofpoor performance trials only forsome sessions. Inaddition, training with\\nfeedback didnotimprove subjects’ metaknowledge performance. Ifanything, subjects’ meta-\\nknowledge performance actuallydeclined during feedback.\\nThe benefits ofvisual working memory practice arehighly stimulus specific\\nPracticing ononevisual working memory task ledtoimproved performance onanother visual\\nworking memory task with thesame stimuli and adifferent response mode (color change\\ndetection) butledtonoimprovement onatask with different stimuli butthesame response\\nmode (orientation whole report). This finding isconsistent with work byGaspar and col-\\nleagues [11] showing that visual working memory training benefits were highly stimulus spe-\\ncific (extensive adaptive training onanobject change detection task didnotconfer benefits to\\nanorientation change detection task). Likewise, Buschkuehl and colleagues [12] recently\\nfound that adaptive visual working memory training yielded highly task-specific\\nWorking memory practice andfeedback\\nPLOS ONE |https://doi.or g/10.137 1/journal.po ne.02032 79 August 30,2018 15/22',\n",
       " 'improvements. Future work isneeded toestablish themechanisms underlying these stimulus-\\nspecific improvements toworking memory performance (e.g. familiarity affecting encoding\\norstorage [32], “chunking” strategies [33], orimproved retrieval [34]). Unfortunately, the\\nstimulus-specificity ofvisual working memory practice greatly limits thescope oftheexpected\\nbenefits ofpractice. Practice may bebeneficial ifthedesired outcome istomore effectively\\nremember ormentally manipulate thesame stimulus set(e.g. thesame setoficons inacom-\\nplex software display), butmay beoflimited utility iftransfer tonovel stimulus setsisdesired.\\nRobust practice benefits with fixed task difficulty\\nFrequently, theuseofanadaptive task isdescribed ascritical foryielding improvements to\\nworking memory performance [35], and direct comparisons have found that adaptive tasks\\nyield larger improvements toperformance than non-adaptive tasks [36–38]. However, when\\ncomparing adaptive and non-adaptive training protocols, itisimportant tocontrol fordiffi-\\nculty, otherwise themanipulation ofadaptiveness canbeconfounded with overall task diffi-\\nculty during training. Forexample, work byvon Bastian and Eschen [39] found that there was\\nnodifference between adaptive and non-adaptive working memory practice when overall diffi-\\nculty wasmatched. Thus, mere exposure toavariety ofdifficulty levels hasbeen shown toyield\\nlarge increases inworking memory performance.\\nInthecurrent study, wefound that exposure toadifficult condition alone wassufficient to\\nyield robust increases invisual working memory performance. Participants never encountered\\nanyeasy trials (alltrials were setsize6),yetweobserved robust improvements inperformance\\nacross sessions. The effects ofadaptive versus non-adaptive procedures have yettobedirectly\\ncompared with asimilar visual working memory task, sowecannot make strong claims about\\ntheefficacy ofadaptive versus non-adaptive practice inthiscontext. However, ourfinding of\\nrobust practice effects isconsistent with previous observations ofimprovements tovisual\\nworking memory performance across sessions, both foradaptive [12] and non-adaptive [4]\\ntasks. Aninteresting open question forfuture work istowhat extent participants may use\\n“self-set” adaptive strategies when they areonly given difficult trials, and whether such self-set\\ngoals underlie thepractice benefits that weobserved. Since awhole report task requires report-\\ningeach item individually, participants’ improvement may beaided byself-selected goals that\\nchange across practice, forexample, “To start out, I’lljusttrytoget2correct and then guess on\\ntherest.”\\nSpacing may influence visual working memory practice benefits\\nHere, wereported robust improvements tovisual working memory performance with practice,\\nconsistent with previous work [4,11,12]. However, inconsistent with thiscore result, astudy by\\nOlson and Jiang [40] reported that visual working memory isimpervious totraining. We\\nthink that thespacing ofpractice may explain thediscrepancy between these tworesults. In\\nOlson and Jiang (2004), allofthetraining was“massed” within asingle practice session. Con-\\nversely, studies reporting robust practice effects onvisual working memory performance have\\nspaced practice across multiple days.\\nA“spacing effect” isdefined byalarger performance benefit when anequivalent amount of\\npractice isseparated intime asopposed tobeing massed within asingle practice session. Spac-\\ningeffects have been extremely well-characterized inthedomains ofepisodic memory [41,42]\\nand motor learning [43], buthave notbeen formally quantified intheworking memory litera-\\nture. However, aqualitative assessment oftheworking memory literature suggests that spacing\\neffects inworking memory may respect anon-monotonic function, likethat reported forepi-\\nsodic memory [44,45]. With short “block breaks” within asingle session (e.g., minutes),\\nWorking memory practice andfeedback\\nPLOS ONE |https://doi.or g/10.137 1/journal.po ne.02032 79 August 30,2018 16/22',\n",
       " 'working memory practice effects areabsent [40]. With intermediate spacing (e.g., 1day– 1\\nweek), arobust practice benefit isobserved from thefirst tothesecond session [4,11,12]. How-\\never, with more distant spacing (e.g., many weeks tomonths), norobust practice benefit is\\nobserved (asforthePassive and Active Control Groups, Fig4A;also see[46]). Wethink thisis\\nanintriguing qualitative pattern ofresults, butfuture work isneeded tosystematically quantify\\ntheeffects ofspaced practice onvisual working memory performance.\\nPrevious exposure totasks may reduce power\\nWefound that practice decreased abetween-groups effect size, which hasprofound implica-\\ntions forother studies attempting tocalculate power formulti-session data based onsingle-\\nsession pilot studies. Wereanalyzed anearlier dataset inwhich wecould make thesame com-\\nparison (feedback versus no-feedback) inboth awithin-subjects and abetween-subjects man-\\nner. Asexpected, theoverall between-subjects effect sizewassmaller than thewithin-subjects\\neffect size. Critically, thesame between-subjects effect sizewasreduced after allparticipants\\nhadexperience with thetask. This suggests that power estimates made from single-session task\\nperformance may notgeneralize well tomulti-session studies. Thus, practice effects should be\\nconsidered when planning sample sizes forlarge training studies.\\nFeedback about accuracy didnotimprove metacognition\\nConsistent with previous work, weobserved areliable increase inmetaknowledge perfor-\\nmance with practice [47]. Surprisingly, however, wefound that subjects’ metaknowledge per-\\nformance wasworse during sessions with feedback. This finding suggests that feedback may\\nactually undermine thegoal ofimproving metaknowledge ifthefeedback leads participants to\\nspend lesseffort onmonitoring their own performance. Forexample, iffeedback emphasizes\\nimproving accuracy, then participants may neglect thesecondary task ofaccurately rating\\ntheir metaknowledge tobetter maximize available resources fortheworking memory task.\\nBecause ourfeedback focused onmemory accuracy and didnotreward metacognitive accu-\\nracy, wethink that participants engaged insuch atradeoff.\\nNote, wehave used theterm “with feedback” todiscuss behavioral effects related toourspe-\\ncific weighted feedback intervention relative tonofeedback. However, weonly tested asingle\\nfeedback manipulation inthisstudy, soourconclusions should notbeinterpreted tomean\\nthat allfeedback manipulations would yield similar effects. Changes tothetiming [48,49], fre-\\nquency [50], content [15,16], ormodality [16,51,52] offeedback would beexpected tomodu-\\nlatetheeffect offeedback onbehavioral performance. Manipulating theprecise nature of\\nperformance feedback would beuseful forinvestigating thelimits offeedback-related\\nimprovements toworking memory and metaknowledge performance. Forexample, anew\\nweighted feedback design which combines both working memory accuracy and metacognitive\\naccuracy may prove effective atboosting both working memory performance and metacogni-\\ntion. Finally, future work employing near real-time feedback about behavioral [53,54], neural\\n[55–59], and physiological [60] markers ofattentional state could beused toprovide partici-\\npants precise, theoretically-driven feedback and totestthespecific mechanisms underlying\\nfeedback-related improvements.\\nMixed evidence that crossword puzzles areanadequate active control\\nOne critical aspect ofanyintervention isthechoice ofacontrol group. The problem ofplacebo\\neffects isparticularly pernicious inmulti-session behavioral interventions. Spurious placebo-\\nlikeeffects might begenerated from differential amounts ofexperimenter contact, task engage-\\nment, orexpectations forimprovement [3,13,29]. Ifthese issues cannot beavoided altogether,\\nWorking memory practice andfeedback\\nPLOS ONE |https://doi.or g/10.137 1/journal.po ne.02032 79 August 30,2018 17/22',\n",
       " 'they canatleast bemeasured. Asanexample, Boot and colleagues [29] performed anonline\\nstudy where they measured theexpectations ofparticipants. Participants viewed atraining task\\n(e.g. action video game) and then rated whether they thought bypracticing that task they\\nmight improve onsome other tasks and abilities. Unfortunately, Boot and colleagues found\\nthat expectations were notwell matched bycommonly-used control tasks (e.g. Tetris). Here,\\nweused crossword puzzle practice asacontrol forworking memory practice. Because people\\ncommonly believe that doing crossword puzzles reflects intelligence and canallow onetostay\\nmentally “fit” [61,62], wethought thiscontrol task would have agood chance ofleading sub-\\njects tobelieve that practice benefits were expected. Others, however, have speculated that\\ncrossword puzzles donotadequately control fordemand and expectations relative toworking\\nmemory tasks [63].\\nInourexperiment, subjective measures ofoverall effort and perceived improvement (rated\\nasaverage improvement forallpre- and post-test tasks) revealed mixed results fortheefficacy\\nofcrossword puzzle control groups. Ontheonehand, those inthecrossword puzzle group\\nreceived thesame amount ofexperimenter contact and didnotreport lower levels ofeffort\\nthroughout theexperiment, indicating that they stayed engaged throughout thetraining ses-\\nsions. Ontheother hand, they reported lessperceived improvement than those intheworking\\nmemory groups. Like theworking memory groups, thecrossword puzzle group didactually\\nimprove more ontheir trained task than theother groups. So,itwould beaccurate forthis\\ngroup toreport that they improved slightly more (for theaverage across allofthetasks) than\\nthepassive control group. However, thiswasnotthecase. Instead, theactive control group\\nreported equivalent perceived improvement tothepassive control group and lower perceived\\nimprovement than thetwoworking memory practice groups. Thus, itisunclear whether or\\nnotcrossword puzzle training adequately controlled forparticipant’s expectations relative to\\nworking memory practice groups, and future work isneeded tomore precisely characterize\\nparticipants’ beliefs and expectations about awide array ofpotential control tasks.\\nConclusions\\nWefound robust practice-related improvements tovisual working memory performance,\\nboth with and without performance feedback. Performance feedback somewhat augmented\\npractice-related improvements, buttheeffects offeedback were somewhat weak and transient.\\nOnce subjects were well-practiced ontheworking memory task, thebenefits offeedback dissi-\\npated. Inaddition, thebenefits offeedback didnotpersist after feedback wastaken away inthe\\npost-test session. Participants gotbetter atmonitoring their own performance with practice,\\nbutfeedback didnotplay arole inthisimprovement. Ifanything, trial-by-trial feedback actu-\\nallyreduced participants’ self-monitoring and metacognitive accuracy. Finally, despite robust,\\nstable improvements inworking memory ability with practice, wefound noevidence that\\npractice benefits ledtoconcomitant improvements inother cognitive abilities.\\nSupporting information\\nS1Table. Correlations between pre-test measures.\\x03p<.05\\x03\\x03p<.01.\\n(DOCX)\\nS2Table. Correlations between post-test measures.\\x03p<.05\\x03\\x03p<.01.\\n(DOCX)\\nS3Table. Reliability ofmeasures: Uncorrected correlation coefficient between pre- and\\npost-test score.n.s.p>.05,allothersp<.01.\\n(DOCX)\\nWorking memory practice andfeedback\\nPLOS ONE |https://doi.or g/10.137 1/journal.po ne.02032 79 August 30,2018 18/22',\n",
       " 'Acknowledgmen ts\\nWethank Irida Mance forassistance with task preparation and data collection, and wethank\\nRichard Matullo fororganization ofsubject payments and data collection. Thanks also toWill\\nMcGuirk, David Grady, and Emily Taylor forassistance with data collection.\\nAuthor Contributions\\nConceptualization: Kirsten C.S.Adam, Edward K.Vogel.\\nData curation: Kirsten C.S.Adam.\\nFormal analysis: Kirsten C.S.Adam.\\nFunding acquisition: Edward K.Vogel.\\nInvestigation: Kirsten C.S.Adam.\\nMethodology: Kirsten C.S.Adam, Edward K.Vogel.\\nProject administration: Kirsten C.S.Adam.\\nSoftware: Kirsten C.S.Adam.\\nSupervision: Edward K.Vogel.\\nValidation: Kirsten C.S.Adam.\\nVisualization: Kirsten C.S.Adam.\\nWriting –original draft: Kirsten C.S.Adam.\\nWriting –review &editing: Kirsten C.S.Adam, Edward K.Vogel.\\nReferences\\n1. Jaeggi SM, Buschkuehl M,Jonides J,Perrig WJ. Improving fluid intelligenc ewith training onworking\\nmemory. Proc Natl Acad Sci.2008; 105: 6829–6 833. https://doi.or g/10.107 3/pnas.08 01268105 PMID:\\n18443283\\n2. Melby-Le rvåg M,Hulme C.Isworking memory training effective? Ameta-ana lytic review. Dev Psychol.\\n2013; 49:270–29 1.https://doi.or g/10.103 7/a0028228 PMID: 226124 37\\n3. Shipstea dZ,Redick TS,Engle RW. Isworking memory training effective? Psychol Bull. 2012; 138:\\n628–654. https:// doi.org/10.10 37/a002 7473 PMID: 22409508\\n4. XuZ,Adam KCS, Fang X,Vogel EK.The reliability andstability ofvisual working memory capacity.\\nBehav Res Methods .2017; https://doi.or g/10.375 8/s13428-017- 0886-6\\n5. Adam KCS, Mance I,Fukuda K,Vogel EK.The Contributi onofAttentio nalLapses toIndividual Differ-\\nences inVisual Working Memory Capacity. JCogn Neurosc i.2015; 27:1601–1 616. https://doi.or g/10.\\n1162/jocn _a_00811 PMID: 258117 10\\n6. Huang L.Visual working memory isbetter characteriz edasadistribute dresource rather than discrete\\nslots. JVis.2010; 10:8–8. PMID: 21135255\\n7. Rouder JN,Morey RD, Cowan N,Zwilling CE,Morey CC, Pratte MS. Anassessm entoffixed-capa city\\nmodels ofvisual working memo ry.Proc Natl Acad SciUSA.2008; 105: 5975–59 79.https://doi.or g/10.\\n1073/pnas .0711295105 PMID: 18420818\\n8. Kane MJ,Brown LH,McVay JC,Silvia PJ,Myin-Germ eysI,Kwapil TR.ForWhom theMind Wanders,\\nandWhen: AnExperience-S ampling Study ofWorking Memory andExecutiv eControl inDaily Life. Psy-\\nchol Sci.2007; 18:614–621. https://doi.or g/10.1111/ j.1467-9280 .2007.01948. xPMID: 176148 70\\n9. Kane MJ,Gross GM, Chun CA,Smeekens BA,Meier ME, Silvia PJ,etal.ForWhom theMind Wanders ,\\nandWhen, Varies Across Laboratory andDaily-Life Settings. Psychol Sci.2017; https:// doi.org/10.\\n1177/09567 97617706086 PMID: 287197 60\\n10. Reason JT.Lapses ofattention ineveryday life.In:Parasurama nR,Davies DR, editors. Varieties of\\nAttention. Orlando, Florida: Academic Press; 1984. pp.515–549.\\nWorking memory practice andfeedback\\nPLOS ONE |https://doi.or g/10.137 1/journal.po ne.02032 79 August 30,2018 19/22',\n",
       " '11. Gaspar JG,Neider MB, Simons DJ,McCarley JS,Kramer AF.Change Detecti on:Training andTrans-\\nfer.Hamed SB,editor. PLoS ONE. 2013; 8:e67781. https://doi.or g/10.1371/ journal.pon e.0067781\\nPMID: 238407 75\\n12. Buschkuehl M,Jaeggi SM, Mueller ST,Shah P,Jonides J.Training Change Detecti onLeads toSub-\\nstantial Task-Speci ficImprovem ent.JCogn Enhanc. 2017; 1:419–433. https:// doi.org/10.10 07/\\ns41465-017 -0055-y\\n13. Redick TS,Shipstead Z,Harrison TL,Hicks KL,Fried DE,Hambrick DZ,etal.Noevidence ofintelli-\\ngence improvem entafter working memory training: Arandom ized, placebo -controlled study. JExp Psy-\\nchol Gen. 2013; 142: 359–379. https://d oi.org/10.103 7/a00290 82PMID: 22708717\\n14. Blacker KJ,Negoita S,Ewen JB,Courtney SM. N-back Versus Complex Span Working Memory Train-\\ning.JCogn Enhanc .2017; 1:434–454. https://doi.or g/10.1007/ s41465-017- 0044-1 PMID: 29430567\\n15. Adam KCS, Vogel EK.Reducing failures ofworking memory with perform ance feedback. Psychon Bull\\nRev. 2016; 23:1520–1527. https://doi.or g/10.375 8/s13423 -016-1019 -4PMID: 26961905\\n16. Miranda AT,Palmer EM. Intrinsic motivation andattention alcapture from gamelike features inavisual\\nsearch task. Behav Res Methods. 2014; 46:159–172. https://do i.org/10.3758 /s13428- 013-0357- 7\\nPMID: 238356 49\\n17. Adam KCS, Vogel EK.Confident failures: Lapses ofworking memory reveal ametacogniti veblind spot.\\nAtten Percep tPsychophys .2017; 79:1506–152 3.https://doi.or g/10.3758/ s13414-017- 1331-8 PMID:\\n28470554\\n18. Dweck CS.Self-theories :their roleinmotivation, personality ,anddevelopme nt.Philadelph ia,Pa.: Psy-\\nchology Press; 2000.\\n19. Jaeggi SM, Buschkuehl M,Shah P,Jonides J.The roleofindividu aldifferences incognitive training and\\ntransfer. Mem Cognit. 2014; 42:464–480. https://d oi.org/10.375 8/s13421 -013-0364 -zPMID: 2408191 9\\n20. Elliott ES,Dweck CS.Goals: Anapproach tomotivat ionandachievement. JPers Soc Psychol. 1988;\\n54:5–12. https:/ /doi.org/10.10 37/0022 -3514.54.1.5 PMID: 334680 8\\n21. Brainard DH. The Psychophy sics Toolbox. Spat Vis.1997; 10:433–436. https://doi.or g/10.116 3/\\n156856897X 00357 PMID: 9176952\\n22. Pelli DG. The VideoToolbo xsoftware forvisual psychophy sics: transformi ngnumbers intomovies. Spat\\nVis.1997; 10:437–442. https://do i.org/10.1163 /1568568 97X00366 PMID: 9176953\\n23. Luck SJ,Vogel EK.The capacity ofvisual working memory forfeature sandconjunctio ns.Nature. 1997;\\n390: 279–281 .https://doi.or g/10.1038/ 36846 PMID: 9384378\\n24. Hallett PE.Primary andsecondar ysaccad estogoals defined byinstruction s.Vision Res. 1978; 18:\\n1279–1296. https:/ /doi.org/10.10 16/0042 -6989(78)9021 8-3PMID: 726270\\n25. Unsworth N,Spillers GJ,Brewer GA, McMillan B.Attention control andtheantisaccade task: A\\nresponse time distribu tionanalysis. Acta Psych ol(Amst). 2011; 137: 90–100. https://doi.or g/10.101 6/j.\\nactpsy.2 011.03.004 PMID: 214705 85\\n26. Raven JC.Advanced Progressiv eMatrices: Sets IandII:Plan anduseofthescale with areport of\\nexperime ntalwork carried outbyG.A. Foulds andA.R. Forbes. London :H.K.Lewis; 1965.\\n27. Dweck CS,Leggett EL.Asocial-cog nitive approac htomotivation andpersona lity.Psychol Rev. 1988;\\n95:256–273. https://doi.or g/10.1037/ 0033-295X .95.2.256\\n28. Buschkuehl M,Hernandez -Garcia L,Jaeggi SM, Bernard JA,Jonides J.Neural effects ofshort-term\\ntraining onworking memory. Cogn Affect Behav Neurosci. 2014; 14:147–160. https://do i.org/10.3758 /\\ns13415-013 -0244-9 PMID: 24496717\\n29. Boot WR, Simons DJ,Stothart C,Stutts C.The Pervasive Problem With Placebo sinPsychology :Why\\nActive Control Groups AreNotSufficien ttoRule OutPlacebo Effects. Perspect Psychol Sci.2013; 8:\\n445–454. https:// doi.org/10.11 77/1745 69161349127 1PMID: 261731 22\\n30. Faul F,Erdfelder E,Buchne rA,Lang A-G. Statistic alpower analyses using G*Power 3.1:Tests forcor-\\nrelation andregressio nanalyses. Behav Res Methods. 2009; 41:1149–1160. https://doi.or g/10.3758/\\nBRM.41.4. 1149 PMID: 19897823\\n31. Faul F,Erdfelder E,Lang A-G, Buchne rA.G*Pow er3:Aflexible statistic alpower analysis program for\\nthesocial, behavio ral,andbiomedical science s.Behav Res Methods .2007; 39:175–191. https://doi.\\norg/10.3758/ BF03193146 PMID: 176953 43\\n32. XieW,Zhang W.Familiar ityincreases thenumber ofremember edPoke´mon invisual short-te rmmem-\\nory.Mem Cognit. 2017; 45:677–689. https://doi.o rg/10.3758/s13 421-016-06 79-7 PMID: 27933560\\n33. Cowan N.The magical number 4inshort-te rmmemory: areconsideratio nofmental storage capacity.\\nBehav Brain Sci.2001; 24:87–114; discussi on114–185. https://doi. org/10.1017/S 0140525X01 003922\\nPMID: 115152 86\\nWorking memory practice andfeedback\\nPLOS ONE |https://doi.or g/10.137 1/journal.po ne.02032 79 August 30,2018 20/22',\n",
       " '34. Souza AS,Rerko L,Oberauer K.Getting more from visual working memory :Retro-cue senhance\\nretrieval andprotect from visual interference. JExp Psychol Hum Percept Perform. 2016; 42:890–91 0.\\nhttps://doi.or g/10.103 7/xhp000 0192 PMID: 26752731\\n35. Lo¨vde´nM,Ba¨ckman L,Lindenberg erU,Schaefer S,Schmiede kF.Atheoretic alframework forthe\\nstudy ofadult cognitive plasticity. Psychol Bull. 2010; 136: 659–676. https:/ /doi.org/10.10 37/a002 0080\\nPMID: 205651 72\\n36. Klingberg T.Training andplasticity ofworking memory. Trends Cogn Sci.2010; 14:317–324. https://\\ndoi.org/10.10 16/j.tics.2010 .05.002 PMID: 20630350\\n37. Klingberg T,Fernell E,Olesen PJ,Johnson M,Gustafss onP,Dahlstro ¨mK,etal.Comp uterized Train-\\ningofWorking Memory inChildren With ADHD-A Randomiz ed,Controlle dTrial. JAmAcad Child Ado-\\nlesc Psychiatry. 2005; 44:177–186. https://doi.or g/10.109 7/00004583- 2005020 00-00010 PMID:\\n15689731\\n38. Holmes J,Gathercole SE,Dunning DL.Adaptive training leads tosustained enhance ment ofpoor work-\\ningmemory inchildren. Dev Sci.2009; 12:F9–F15. https://doi.or g/10.111 1/j.1467-768 7.2009.0 0848.x\\nPMID: 196350 74\\n39. vonBastian CC, Eschen A.Does working memory training have tobeadaptive? Psychol Res. 2016;\\n80:181–194. https://doi.or g/10.1007/ s00426-015- 0655-z PMID: 25716189\\n40. Olson IR,Jiang Y.Visual short-term memory isnotimproved bytraining. Mem Cognit. 2004; 32:1326–\\n1332. https://d oi.org/10.375 8/BF032 06323 PMID: 15900926\\n41. Rohrer D,Pashler H.Increasing Retention Without Increasing Study Time. Curr DirPsychol Sci.2007;\\n16:183–186. https://doi.or g/10.1111/ j.1467-8721 .2007.00500 .x\\n42. Underwood BJ.Ten years ofmassed practice ondistributed practice. Psychol Rev. 1961; 68:229–247.\\nhttps://doi.or g/10.103 7/h0047516\\n43. Shea CH, LaiQ,Black C,Park J-H. Spacing practice sessions across days benefits thelearning of\\nmotor skills. Hum Mov Sci.2000; 19:737–76 0.https://doi.or g/10.1016 /S0167-945 7(00)0002 1-X\\n44. Cepeda NJ,VulE,Rohrer D,Wixted JT,Pashler H.Spacing Effects inLearning: ATemporal Ridgelin e\\nofOptimal Retent ion.Psychol Sci.2008; 19:1095–1 102. https://doi.or g/10.111 1/j.1467-928 0.2008.\\n02209.x PMID: 19076480\\n45. Cepeda NJ,Coburn N,Rohrer D,Wixted JT,Mozer MC, Pashler H.Optimizin gDistributed Practice:\\nTheoretic alAnalysis andPractical Implications .Exp Psychol. 2009; 56:236–246. https://doi. org/10.\\n1027/1618-3 169.56.4 .236 PMID: 194393 95\\n46. Johnson MK, McMah onRP,Robinson BM, Harvey AN,Hahn B,Leonard CJ,etal.The relations hip\\nbetween working memory capacity andbroad measures ofcognitive ability inhealthy adults andpeople\\nwith schizophre nia.Neuropsyc hology. 2013; 27:220–229. https://doi.or g/10.103 7/a0032060 PMID:\\n23527650\\n47. Rademak erRL,Pearson J.Training Visual Imagery: Improvem ents ofMetac ognition, butnotImagery\\nStrength. Front Psychol. 2012; 3.https://doi. org/10.3389/fp syg.2012. 00224 PMID: 22787452\\n48. Opitz B,Ferdinan dNK,Mecklinger A.Timing Matters: The Impact ofImmediate andDelayed Feedba ck\\nonArtificial Languag eLearning. Front Hum Neurosci. 2011; 5.https://doi.or g/10.338 9/fnhum.20 11.\\n00008 PMID: 213440 08\\n49. Lieberman DA,Vogel ACM, Nisbet J.Short Article: Why dotheEffects ofDelaying Reinforcem entin\\nAnimals andDelaying Feedback inHumans Differ? AWorking-M emory Analysis. QJExp Psychol.\\n2008; 61:194–20 2.https://doi.or g/10.108 0/1747021070 155750 6PMID: 17886159\\n50. Lam CF,DeRue DS,Karam EP,Hollenbeck JR.The impact offeedback frequency onlearning andtask\\nperformanc e:Challeng ingthe“more isbetter” assump tion. Organ Behav Hum Decis Process. 2011;\\n116: 217–228 .https://doi.or g/10.1016/ j.obhdp.2011.0 5.002\\n51. Burke JL,Prewett MS, Gray AA,Yang L,Stilson FRB, Coovert MD, etal.Comparing theeffects of\\nvisual-au ditory andvisual-tactil efeedback onuser perform ance: ameta-ana lysis. ACM Press; 2006. p.\\n108. https://do i.org/10.1145 /1180995 .1181017\\n52. Sigrist R,Rauter G,Riener R,Wolf P.Augmen tedvisual, auditory, haptic, andmultimodal feedback in\\nmotor learning: Areview. Psychon BullRev. 2013; 20:21–53. https://doi. org/10.3758/s 13423-012-\\n0333-8 PMID: 231326 05\\n53. deBettenc ourt MT, Norman KA,Turk-Browne NB.Forgetting from lapses ofsustained attention. Psy-\\nchon BullRev. 2017; https://doi.or g/10.3758/ s13423-017- 1309-5 PMID: 285850 55\\n54. Jones PR.Sitstillandpayattention :Using theWiiBalance -Board todetect lapses inconcentra tionin\\nchildren during psychophy sical testing. Behav Res Methods. 2018; https://doi. org/10.3758/s 13428-\\n018-1045- 4PMID: 2977090 7\\nWorking memory practice andfeedback\\nPLOS ONE |https://doi.or g/10.137 1/journal.po ne.02032 79 August 30,2018 21/22',\n",
       " '55. deBettenc ourt MT, Cohen JD,LeeRF,Norman KA,Turk-B rowne NB.Closed-lo optraining ofattention\\nwith real-time brain imaging. NatNeurosci. 2015; 18:470–475. https:// doi.org/10.10 38/nn.39 40PMID:\\n25664913\\n56. Fukuda K,Woodman GF. Predicting andImproving Recognition Memo ryUsing Multiple Electroph ysio-\\nlogical Signals inReal Time. Psychol Sci.2015; 26:1026–1037. https://do i.org/10.1177 /\\n09567976155 78122 PMID: 26040757\\n57. LaConte SM. Decod ingfMRI brain states inreal-time. NeuroImage .2011; 56:440–454. https:// doi.org/\\n10.1016/ j.neuroimage.2 010.06.0 52PMID: 206009 72\\n58. Weiskopf N,Mathiak K,Bock SW, Scharnow skiF,Veit R,Grodd W,etal.Principles ofaBrain-Com-\\nputer Interface (BCI) Based onReal-Time Functiona lMagnetic Resonance Imaging (fMRI). IEEE Trans\\nBiomed Eng. 2004; 51:966–970. https:// doi.org/10.11 09/TBME .2004.82 7063 PMID: 15188865\\n59. Miran S,Akram S,Sheikhat tarA,Simon JZ,Zhang T,Babad iB.Real-Tim eTracking ofSelective Audi-\\ntoryAttentio nFrom M/EEG :ABayesian Filtering Approac h.Front Neurosci. 2018; 12.https://doi.or g/\\n10.3389/ fnins.2018. 00262 PMID: 29765298\\n60. Matho ˆtS,Melmi J-B, vanderLinden L,Van derStigchel S.The Mind-Writing Pupil: AHuma n-Computer\\nInterface Based onDecoding ofCovert Attentio nthrough Pupillomet ry.vanRijn H,editor. PLOS ONE.\\n2016; 11:e01488 05.https://doi.or g/10.137 1/journal.po ne.014880 5PMID: 26848745\\n61. Hambrick DZ,Salthouse TA,Meinz EJ.Predictors ofcrosswor dpuzzle proficiency andmoderators of\\nage-cognit ionrelations. JExp Psychol Gen. 1999; 128: 131–164. PMID: 10406103\\n62. Salthous eTA.Mental Exercise andMental Aging. Evaluati ngtheValidity ofthe“Use ItorLose It”\\nHypothes is.Perspect Psychol Sci.2006; 1:68–87. https://doi.or g/10.111 1/j.1745-691 6.2006.0 0005.x\\nPMID: 261511 86\\n63. Simons DJ,Boot WR, Charness N,Gathercole SE,Chabris CF,Hambrick DZ,etal.Do“Brain-Tr aining”\\nPrograms Work? Psychol SciPublic Interest. 2016; 17:103–186. https://d oi.org/10.117 7/\\n15291006166 61983 PMID: 27697851\\nWorking memory practice andfeedback\\nPLOS ONE |https://doi.or g/10.137 1/journal.po ne.02032 79 August 30,2018 22/22']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "def load_pdf_to_str(file_path: str) -> str:\n",
    "    loader = PyPDFLoader(file_path)\n",
    "    docs = loader.load()\n",
    "    return [page.page_content for page in docs]\n",
    "\n",
    "file_path = \"./assets-resources/sources/improv-visual-working-mem.pdf\"\n",
    "pdf_pages = load_pdf_to_str(file_path)\n",
    "pdf_pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field, field_validator\n",
    "from typing import List, Literal\n",
    "\n",
    "\n",
    "class Evidence(BaseModel):\n",
    "    positions: List[Literal['yes', 'no', 'neutral']] = Field(description=\"A List with 1-3 ternary scores presenting the positions of the paper regarding the query/hypothesis in question as yes|no|neutral.\")\n",
    "    position_descriptions: List[str] = Field(description=\"List with 1-3 statements presenting the position for, against or neutral regarding the query/hypothesis n question.\")\n",
    "    evidence: List[str] = Field(description=\"List of DIRECT QUOTES serve as evidence to support each position.\")\n",
    "\n",
    "    @field_validator('positions', 'position_descriptions', 'evidence')\n",
    "    def validate_list_size(cls, values):\n",
    "        if len(set(map(len, values))) != 1:\n",
    "            print(\"Uncertainty in results, retrying...\")\n",
    "        return values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "SYS_MSG_EVIDENCE = \"\"\"\n",
    "You are a helpful research assistant. Given a research question or hypothesis you\n",
    "will inspect the contents of papers or articles for evidence for or against \n",
    "the respective hypothesis in question. Your output will be 2 fields:\n",
    "- positions: List of ternary scores (yes|no|neutral) presenting the positions of the paper regarding the query/hypothesis in question.\n",
    "- positions_descriptions: List of a short one sentence statements summarizing the position from the text regarding the user's query or hypothesis, like: \"Yes this paper validates this idea by pointing out....\" etc..\n",
    "- evidence: a list with DIRECT QUOTES from the paper containing information that supports and validates each position. It should be one quote to validate each position.\n",
    "\n",
    "All 3 fields should be lists with the same size.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = \"gpt-4o-2024-08-06\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "def inspect_evidence(prompt_question):\n",
    "    response = client.beta.chat.completions.parse(\n",
    "        model=MODEL,\n",
    "        messages=[{\"role\": \"system\", \"content\": SYS_MSG_EVIDENCE},\n",
    "                  {\"role\": \"user\", \"content\": prompt_question}],\n",
    "        response_format=Evidence,\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It's actually the entire first page but bare with me.\n",
    "abstract = pdf_pages[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uncertainty in results, retrying...\n",
      "Uncertainty in results, retrying...\n",
      "Uncertainty in results, retrying...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Evidence(positions=['no', 'neutral'], position_descriptions=['No, this paper does not support the idea as feedback benefits did not persist over time.', 'Neutral, as the study does not find evidence supporting long-term far transfer improvements.'], evidence=['Practicing with feedback improved working memory performance relative to a no-feedback group for some practice sessions. However, the feedback benefits did not persist across all training sessions and did not transfer to a final test session without the feedback.', 'We found only stimulus-specific transfer of visual working memory practice benefits.'])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# source: https://www.semanticscholar.org/paper/Improvements-to-visual-working-memory-performance-Adam-Vogel/e18bbb815cf36aa75ef335787ecd9084d418765e\n",
    "hypothesis = \"Working memory training in humans might lead to long-term far transfer improvements in some cognitive abilities.\"\n",
    "\n",
    "prompt = f\"\"\"\n",
    "Does this abstract: \n",
    "{abstract}\\n\\n\n",
    "presents evidence for the following statement:\n",
    "{hypothesis}\n",
    "\"\"\"\n",
    "\n",
    "output = inspect_evidence(prompt)\n",
    "\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Position: no\n",
      "Position Description: No, this paper does not support the idea as feedback benefits did not persist over time.\n",
      "Evidence: Practicing with feedback improved working memory performance relative to a no-feedback group for some practice sessions. However, the feedback benefits did not persist across all training sessions and did not transfer to a final test session without the feedback.\n",
      "\n",
      "\n",
      "****\n",
      "Position: neutral\n",
      "Position Description: Neutral, as the study does not find evidence supporting long-term far transfer improvements.\n",
      "Evidence: We found only stimulus-specific transfer of visual working memory practice benefits.\n",
      "\n",
      "\n",
      "****\n"
     ]
    }
   ],
   "source": [
    "for p,pd,e in zip(output.positions, output.position_descriptions, output.evidence):\n",
    "    print(f\"Position: {p}\\nPosition Description: {pd}\\nEvidence: {e}\\n\\n\")\n",
    "    print(\"****\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inspect_evidence_for_hypothesis(hypothesis: str, source_content: str):\n",
    "    \"\"\"Inspects the evidence for, against or neutral regarding a research hypothesis.\"\"\"\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "    Does this abstract: \n",
    "    {source_content}\\n\\n\n",
    "    presents evidence for the following statement:\n",
    "    {hypothesis}\n",
    "    \"\"\"\n",
    "\n",
    "    output = inspect_evidence(prompt)\n",
    "    \n",
    "    return output\n",
    "\n",
    "def display_output_evidence(output):\n",
    "    for p,pd,e in zip(output.positions, output.position_descriptions, output.evidence):\n",
    "        print(f\"Position: {p}\\nPosition Description: {pd}\\nEvidence: {e}\\n\\n\")\n",
    "        print(\"****\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Position: yes\n",
      "Position Description: Yes, this paper supports the idea that working memory training leads to long-lasting improvements in fluid intelligence.\n",
      "Evidence: Results showed that the training group significantly improved performance in verbal WM and fluid intelligence compared to the active control group, immediately after training and after 6 months.\n",
      "\n",
      "\n",
      "****\n"
     ]
    }
   ],
   "source": [
    "# source for this abstract: https://pubmed.ncbi.nlm.nih.gov/35107614/\n",
    "hypothesis_fluid_intelligence = \"Working memory training might lead to long lasting improvements in fluid intelligence.\"\n",
    "abstract_with_argument_for_improvement_in_fluid_intelligence = \"\"\"\n",
    "Abstract\n",
    "Process-based working memory (WM) training in typically developing children usually leads to short- and long-term improvements on untrained WM tasks. However, results are mixed regarding far transfer to academic and cognitive abilities. Moreover, there is a lack of studies jointly evaluating the different types of transfer, using an adequate design and considering motivational factors. In addition, evidence is needed about how pre-training performance is related to individual differences in training-induced transfer. Therefore, this study aimed to implement and evaluate the efficacy of a computerized process-based WM training in typically developing school-age children. Near and far transfer effects were evaluated both immediately after training and after 6 months, as well as individual differences in training-induced transfer. The sample was composed of 89 typically developing children aged 9-10 years (M = 9.52, SD = 0.30), who were randomized to a WM training group or an active control group. They were evaluated at pre-training, post-training, and follow-up phases with measures of visuospatial and verbal WM, reading comprehension, math computation, and fluid intelligence. Results showed that the training group significantly improved performance in verbal WM and fluid intelligence compared to the active control group, immediately after training and after 6 months. Trained children with lower initial performance in verbal WM or fluid intelligence showed greater transfer gains. No group differences were found in motivational factors. Findings of this study suggest that process-based WM training may promote transfer to cognitive abilities and lead to compensation effects of individual differences in typically developing school-age children.\n",
    "\"\"\"\n",
    "\n",
    "output = inspect_evidence_for_hypothesis(hypothesis_fluid_intelligence, abstract_with_argument_for_improvement_in_fluid_intelligence)\n",
    "display_output_evidence(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(output.positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(output.position_descriptions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(output.evidence)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "augment-research-workflows",
   "language": "python",
   "name": "augment-research-workflows"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
